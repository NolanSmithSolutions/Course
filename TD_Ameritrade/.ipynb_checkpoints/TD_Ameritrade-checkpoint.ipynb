{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD Ameritrade – Python API\n",
    "The TD Ameritrade API allows users to easily execute trades and pull both fundamental and technical data on all public equity and debt securities.  It also offers data on publicly traded derivatives such as stock options, index & commodity futures, and interest rate swaps.\n",
    "\n",
    "### Set Up\n",
    "1.\tGo to https://developer.tdameritrade.com/\n",
    "2.\tClick “Register”\n",
    "3.\tFill in requested fields\n",
    "4.\tOnce Registered, click on “My Apps”\n",
    "5.\tSelect “Add a new App”\n",
    "6.\tFill out the fields as follows \n",
    "7.\tOnce the app is approved, click on the app name and navigate to the “KEYS” tab: \n",
    "8.\tNow that your app is registered copy the “Key” from the above section, and head over to the included Jupyter notebook to test out some of the functionality of the API.\n",
    "\n",
    "### Python Set up for the API\n",
    "Now that your app is registered, you will be able to pull a wealth of info from the API.\n",
    "#### Needed Packages\n",
    "1.\trequests\n",
    "2.\tpandas\n",
    "3.\ttime\n",
    "4.  matplotlib\n",
    "5.  numpy\n",
    "6.  seaborn\n",
    "7.  statsmodels.api\n",
    "8.  math\n",
    "9. statistics\n",
    "\n",
    "#### Needed Configuration Inputs\n",
    "1.\tTicker file path.  This is a CSV file that you will create that has the set of tickers you wish to analyze.  Place this file in your download's folder.\n",
    "2.\tAPI Key: pulled from the developer page\n",
    "3.\tDefine these required configurations in the Jupyter notebook:\n",
    "  \n",
    "\n",
    "### Data & Analysis\n",
    "\n",
    "1. Downloading fundamental data\n",
    "2. Downloading pricing data\n",
    "3. Calculating Annualized Returns\n",
    "4. Running a Regression Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###Libraries & Paths##\n",
    "######################\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snagging Downloaded Files\n",
    "\n",
    "The \"get_download_path\" function allows python to find your downloads folder's filepath and use it pull open your ticker list csv file.  The output of the below cell should be a list of the tickers you inputted in the ticker list csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_path():\n",
    "    \"\"\"Returns the default downloads path for linux or windows\"\"\"\n",
    "    if os.name == 'nt':\n",
    "        import winreg\n",
    "        sub_key = r'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders'\n",
    "        downloads_guid = '{374DE290-123F-4565-9164-39C4925E467B}'\n",
    "        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, sub_key) as key:\n",
    "            location = winreg.QueryValueEx(key, downloads_guid)[0]\n",
    "        return location\n",
    "    else:\n",
    "        return os.path.join(os.path.expanduser('~'), 'downloads')\n",
    "\n",
    "ticker_path = get_download_path()+'/Ticker_List.csv'\n",
    "key = ''  ##PUT YOUR KEY HERE\n",
    "\n",
    "tickers_file = pd.read_csv(ticker_path, header=None)\n",
    "tickers = []\n",
    "for ticker in tickers_file.values:\n",
    "    tickers.append(ticker[0])\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Edits\n",
    "Uncomment out the below cell and edit the list's content to replace the tickers you wish to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tickers\n",
    "tickers = ['AAPL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Functions\n",
    "While this code block does not run anything on its own, it holds functions that will be used later in the program.  The TD Ameritrade API contains functions that don't always output data in the most clean (useable) format, so we have developed some functions that \"scrub\" the output so that it returns in a better format.  Each function will be examined more thouroughly as we go through the lecture, but they will allow us to analyze a public stock from both a quantitative and qualitative perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_hist(ticker,period,key):\n",
    "    time.sleep(1)\n",
    "    endpoint = 'https://api.tdameritrade.com/v1/marketdata/'+ticker+'/pricehistory'\n",
    "\n",
    "    ##Define Payload\n",
    "    payload = {'apikey': key,\n",
    "    'periodType': 'year',\n",
    "    'peirod':period,\n",
    "    'frequencyType':'daily'}\n",
    "\n",
    "    ### make request\n",
    "    try:\n",
    "        content = requests.get(url = endpoint, params = payload)\n",
    "    except:\n",
    "        print('API error, please review.')\n",
    "        \n",
    "    ### Convert to dictionary\n",
    "    dictlist = []\n",
    "    data = content.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        temp = [key,value]\n",
    "        dictlist.append(temp)\n",
    "        \n",
    "    try:\n",
    "        hist_data = pd.DataFrame(dictlist[0][1])\n",
    "        hist_data['ticker'] = ticker\n",
    "        hist_data['datetime'] = pd.to_datetime(hist_data['datetime'],unit='ms')\n",
    "        return hist_data\n",
    "    except:\n",
    "        df = pd.DataFrame()\n",
    "        return df\n",
    "    \n",
    "\n",
    "def get_fundamental_from_td(ticker,key):\n",
    "    time.sleep(1)\n",
    "    endpoint = 'https://api.tdameritrade.com/v1/instruments'\n",
    "    projection = 'fundamental'\n",
    "\n",
    "    ##Define Payload\n",
    "    payload = {'apikey': key,\n",
    "               'symbol' : ticker,\n",
    "                'projection': projection,\n",
    "                }\n",
    "    \n",
    "    ### make request\n",
    "    try:\n",
    "        content = requests.get(url = endpoint, params = payload)\n",
    "    except:\n",
    "        print('API error, please review.')\n",
    "        \n",
    "    ### Convert to dictionary\n",
    "    dictlist = []\n",
    "    data = content.json()\n",
    "    for key, value in data.items():\n",
    "        temp = [key,value]\n",
    "        dictlist.append(temp)\n",
    "        \n",
    "    try:\n",
    "        df = pd.DataFrame(dictlist[0][1]).T.reset_index(drop=True).iloc[0]\n",
    "        return df\n",
    "    except:\n",
    "        print(dictlist)\n",
    "        df = pd.DataFrame()\n",
    "        print(ticker + \" not valid.\")\n",
    "        return df\n",
    "\n",
    "def scrub_fundamental_data(tickers,key):\n",
    "    master = pd.DataFrame()\n",
    "    count = 1\n",
    "    for ticker in tickers:\n",
    "        temp = get_fundamental_from_td(ticker,key)\n",
    "        temp = pd.DataFrame(temp).T\n",
    "        hist_data = get_annual_returns([ticker],key)\n",
    "        try:\n",
    "            temp.columns = ['beta', 'bookValuePerShare', 'currentRatio', 'divGrowthRate3Year',\n",
    "           'dividendAmount', 'dividendDate', 'dividendPayAmount',\n",
    "           'dividendPayDate', 'dividendYield', 'epsChange', 'epsChangePercentTTM',\n",
    "           'epsChangeYear', 'epsTTM', 'grossMarginMRQ', 'grossMarginTTM', 'high52',\n",
    "           'interestCoverage', 'low52', 'ltDebtToEquity', 'marketCap',\n",
    "           'marketCapFloat', 'netProfitMarginMRQ', 'netProfitMarginTTM',\n",
    "           'operatingMarginMRQ', 'operatingMarginTTM', 'pbRatio', 'pcfRatio',\n",
    "           'peRatio', 'pegRatio', 'prRatio', 'quickRatio', 'returnOnAssets',\n",
    "           'returnOnEquity', 'returnOnInvestment', 'revChangeIn', 'revChangeTTM',\n",
    "           'revChangeYear', 'sharesOutstanding', 'shortIntDayToCover',\n",
    "           'shortIntToFloat', 'ticker', 'totalDebtToCapital', 'totalDebtToEquity',\n",
    "           'vol10DayAvg', 'vol1DayAvg', 'vol3MonthAvg']\n",
    "            temp = pd.merge(temp, hist_data, on='ticker')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        master = master.append(temp).reset_index(drop=True)\n",
    "        count+= 1\n",
    "    return master\n",
    "\n",
    "def scrub_price_hist(tickers,key):\n",
    "    master = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        price_data = get_price_hist(ticker,1,key)\n",
    "        master = master.append(price_data, ignore_index=True)\n",
    "    return master\n",
    "\n",
    "def get_annual_returns(tickers,key):\n",
    "    master = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            price_data = get_price_hist(ticker,1,key).iloc[::-1]\n",
    "            return_percent = price_data['close'].iloc[0] / price_data['close'].iloc[-1] -1\n",
    "            df = pd.DataFrame({\"ticker\":ticker,  \n",
    "                               \"Annual_Return_Percent\":return_percent},\n",
    "                               index = [0])\n",
    "            master = master.append(df, ignore_index=True)\n",
    "        except:\n",
    "\n",
    "            print('error with', ticker)\n",
    "    return master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Stock analysis\n",
    "This section will show you how to calculate a stocks beta relative to a market proxy using 1 year daily data.  When\n",
    "picking securities for yours or another's portolio, it is first helpful to know the risk tolerance of the investmentor\n",
    "relative to the risk of investing in the broad market.  Beta will allow us to estimate this for any number of stocks, then\n",
    "make relative conclusions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will get the price history for our short list.\n",
    "aapl_data = scrub_price_hist(tickers,key)\n",
    "aapl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make analysis easier let's only look at the close and date and sort the date in descending order\n",
    "aapl_data = aapl_data[['close','datetime','ticker']]\n",
    "aapl_data = aapl_data.sort_values(by = 'datetime', ascending = False)\n",
    "aapl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column to show daily returns \n",
    "aapl_data['AAPL_Return_%'] = aapl_data['close'] / aapl_data['close'].shift(-1) - 1\n",
    "aapl_data.rename(columns={'close': 'AAPL_Close'}, inplace=True)\n",
    "aapl_data.drop(columns = ['ticker'], inplace = True)\n",
    "aapl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When starting an analysis of a stock, it is helpful to understand how the security performs relative to the market.\n",
    "# To accomplish this, we will use the S&P 500 as a proxy for the market, and calculate the beta of the stock relative \n",
    "# to the proxy.  This cell replicates the above for ticker SPY which is one of the most liquid ETFs the tracks the S&P 500\n",
    "spy_data = scrub_price_hist(['SPY'],key)\n",
    "spy_data = spy_data[['close','datetime','ticker']]\n",
    "spy_data = spy_data.sort_values(by = 'datetime', ascending = False)\n",
    "spy_data['SPY_Return_%'] = spy_data['close'] / spy_data['close'].shift(-1) - 1\n",
    "spy_data.rename(columns={'close': 'SPY_Close'}, inplace=True)\n",
    "spy_data.drop(columns = ['ticker'], inplace = True)\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll merge the two sets\n",
    "consol_data = pd.merge(aapl_data,spy_data,on=['datetime'], how = 'left').dropna() \n",
    "#note that you need to dropna because of how we calc'd returns, the last date in the set will not have a return value \n",
    "\n",
    "consol_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now calc beta using statsmodels\n",
    "x = consol_data[['SPY_Return_%']]\n",
    "y = consol_data[['AAPL_Return_%']]\n",
    "\n",
    "model = sm.OLS(y, x)\n",
    "results = model.fit()\n",
    "print('Beta: '+str(round(results.params[0],2)))\n",
    "\n",
    "# How does this value compare to other sources such as Yahoo Finance (who uses a 5 year monthly model compared to \n",
    "# our 1 year daily)? Should this cause some skepticism when looking at results from models you didn't build?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pull the 1 year price history using the scrub_price_hist function of any stock you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Clean up the output so it mirrors our output for Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Think of another market proxy besides the S&P 500, pull it's data, and clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge the two data sets, so that it mirrors the 'consol_data' variable.  Then merge in the new proxy data and SPY data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the beta of your new stock relative to both SPY and your new market proxy.  Are they different significantly?\n",
    "   Consider why they may be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another common measure of risk: Volatility\n",
    "Much like beta, annual standard deviation of returns (more commonly known as volatility), can be a helpful tool to guage the relative risk a particular asset poses to a portfolio.  Let's see how we might go about calculating that for Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with our Aaple data\n",
    "aapl_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember that the covariance of a random variable with itself is the same as its variance.\n",
    "aapl_vol = math.sqrt(pd.DataFrame([aapl_data['AAPL_Return_%'],aapl_data['AAPL_Return_%']]).T.cov().iloc[0,0])*math.sqrt(252)\n",
    "print('Apple Volatility: '+str(round(aapl_vol*100,2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does this compare to SPY?\n",
    "spy_vol = math.sqrt(pd.DataFrame([spy_data['SPY_Return_%'],spy_data['SPY_Return_%']]).T.cov().iloc[0,0])*math.sqrt(252)\n",
    "print('SPY Volatility: '+str(round(spy_vol*100,2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these results surprising?  Think about the implications of an annual volatility of over 20%, and how such a security would\n",
    "behave if it fell out of the market's favor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Data\n",
    "Many critics argue any form of technical analysis is a waste of time and should be avoided.  Instead, they will argue for\n",
    "fundament analysis, or effectively looking at various accounting measures to understand the health of a firm, and judge it's \n",
    "performance relative to its peers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell pulls the fundamental financial data from TD Ameritrade, cleans it up into a useable format and spits it out \n",
    "# in a nice table format using the Pandas package.  Note that book value per share is not\n",
    "# entirely accurate, all other metrics have been vetted. Let's look at the whole S&P 500.\n",
    "tickers =['AAPL','MSFT','AMZN','FB','GOOGL','GOOG','BRK.B','JNJ','V','PG','JPM','NVDA','UNH','MA','HD','VZ','DIS','NFLX',\n",
    "          'ADBE','PYPL','CRM','MRK','T','INTC','PFE','CMCSA','BAC','WMT','KO','PEP','ABT','CSCO','XOM','TMO','ABBV','MCD',\n",
    "          'COST','ACN','CVX','AMGN','MDT','AVGO','NKE','NEE','BMY','UNP','LIN','LLY','TXN','QCOM','DHR','PM','LOW','HON',\n",
    "          'ORCL','UPS','AMT','IBM','C','SBUX','LMT','MMM','AMD','FIS','CHTR','WFC','RTX','BA','BLK','NOW','INTU','SPGI',\n",
    "          'ISRG','MDLZ','GILD','CAT','MO','CVS','BKNG','ZTS','PLD','TGT','BDX','AXP','ANTM','VRTX','TJX','CCI','DE','D',\n",
    "          'EQIX','TMUS','APD','CL','CI','SYK','GS','MS','CME','DUK','ATVI','ADP','BSX','MMC','CSX','REGN','SO','ITW','CB',\n",
    "          'ICE','SHW','PGR','FISV','HUM','GE','NSC','NEM','FDX','NOC','AMAT','TFC','EW','KMB','USB','MU','GPN','ILMN',\n",
    "          'ADSK','ECL','DG','EL','PNC','AON','MCO','BIIB','LRCX','WM','DD','ADI','BAX','ROP','GM','EMR','ETN','SCHW','AEP',\n",
    "          'LHX','DLR','COP','EA','XEL','DXCM','GIS','CTSH','DOW','EXC','ORLY','HCA','SRE','GD','SBAC','EBAY','ROST','CNC',\n",
    "          'CMG','COF','PSA','TEL','STZ','IDXX','APH','INFO','JCI','SYY','CMI','SNPS','TWTR','MNST','WEC','MET','A','TROW',\n",
    "          'BK','VRSK','TRV','ES','MSCI','ALL','PCAR','PPG','IQV','ZBH','AZO','YUM','MAR','CDNS','HPQ','TT','KR','KLAC','F',\n",
    "          'PRU','WBA','CLX','AFL','CTAS','BLL','ANSS','PEG','MSI','WLTW','PH','HLT','KMI','ROK','SLB','PSX','MCHP','AWK',\n",
    "          'WELL','ADM','AIG','TDG','FAST','WMB','OTIS','GLW','RMD','MCK','ED','SWK','MKC','CARR','BBY','ALXN','XLNX','EOG',\n",
    "          'PAYX','STT','MTD','DHI','FCX','DTE','CHD','ALGN','AVB','O','AME','SWKS','VFC','FTV','PPL','APTV','HSY','SPG',\n",
    "          'CERN','LUV','DLTR','CTVA','MPC','CPRT','WY','LEN','ARE','VRSN','EQR','VLO','EFX','KHC','RSG','FLT','EIX','ETR',\n",
    "          'WST','AJG','AEE','DAL','ODFL','FRC','AMP','TSN','LYB','KSU','MXIM','TFX','LVS','TTWO','KEYS','NTRS','DFS','KMX',\n",
    "          'CMS','AMCR','CAG','MKTX','LH','AKAM','K','VTR','TSCO','VMC','CDW','CTXS','CBRE','INCY','VAR','FE','DOV','PXD',\n",
    "          'COO','FTNT','VIAC','GWW','BR','PEAK','FITB','HOLX','MAS','EXPD','IP','XYL','NDAQ','DPZ','ESS','CAH','BF.B',\n",
    "          'GRMN','ABC','DGX','HIG','GPC','EXR','HRL','DRE','NUE','SYF','EXPE','FMC','NVR','MTB','STE','ZBRA','ULTA','PAYC',\n",
    "          'QRVO','IEX','MAA','SIVB','TIF','HAL','TYL','IFF','CHRW','SJM','MLM','WAT','LNT','CE','URI','BXP','PKI','KEY',\n",
    "          'WAB','NLOK','HPE','RCL','JKHY','ABMD','CINF','EVRG','IR','J','HES','ETFC','OMC','DRI','CFG','JBHT','LDOS','TDY',\n",
    "          'ATO','AES','MGM','IT','FBHS','ANET','RF','PHM','PFG','OKE','WDC','EMN','CNP','STX','WHR','AAP','NTAP','BIO',\n",
    "          'CTL','UDR','HBAN','CBOE','HAS','ALB','LKQ','OXY','PKG','FOXA','XRAY','AVY','CXO','WU','UAL','HSIC','ALLE','BKR',\n",
    "          'RJF','WRB','LW','TXT','UHS','CCL','L','IRM','BWA','RE','DISH','HST','PNW','GL','WRK','LYV','NI','SNA','NRG',\n",
    "          'MYL','WYNN','CPB','JNPR','DVA','ROL','PNR','COG','PWR','FFIV','AIZ','LNC','TAP','CF','REG','AAL','IPG','HWM',\n",
    "          'PRGO','AOS','LB','DISCK','NWL','MOS','RHI','SEE','BEN','HII','CMA','IPGP','VNO','HBI','FRT','MHK','LEG','ZION',\n",
    "          'NWSA','AIV','NLSN','FANG','ALK','DXC','KIM','PVH','APA','NCLH','PBCT','FLIR','NBL','FOX','NOV','TPR','IVZ',\n",
    "          'UNM','SLG','RL','DVN','GPS','FLS','MRO','KSS','DISCA','XRX','HFC','FTI','HRB','UAA','UA','NWS','COTY']\n",
    "fundamental_data=scrub_fundamental_data(tickers,key)\n",
    "fundamental_data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think back to other accounting and finance courses, and assess whether you think the operating metrics of these companies seem to portray a healthy company, or not, and if they seem overvalued based on PE or PS measures.  Remember, there really is no right or wrong answer here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Annual Return Data\n",
    "The below cell pulls the annual return data from TD Ameritrade, cleans it up into a useable format and spits it out in a nice table format using the Pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_returns_df=get_annual_returns(tickers,key)\n",
    "annual_returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Data Frame Info\n",
    "The next few code blocks give us information on how our data is structered, the columns it contains, the data types of the columns (string, integer, float, etc.), summary statistics, null values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fundamental_data.columns:\n",
    "    try:\n",
    "        fundamental_data[col]=fundamental_data[col].astype('float')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Data columns\n",
    "fundamental_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General data statistics\n",
    "fundamental_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame information (null, data type etc)\n",
    "fundamental_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrelated features are generally more powerful predictors\n",
    "# This chart will let us see wich fundamental factors may be most meaningful in predicting returns\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(40, 40))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=14)\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(fundamental_data.corr().round(2)\\\n",
    "            ,linewidths=0.1,vmax=1.0, square=True, cmap=colormap, \\\n",
    "            linecolor='white', annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick a stock we haven't looked at and grab its fundamental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the annual volatility of TQQQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the beta to SPY of AMD as well as its volatility and make a conclusion about its risk profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Get the fundamental data of AMC.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Linear regression models are a great way to test if ratios are even worth looking at.  Lets check based on the stocks we picked above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fundamental_data[['epsTTM', 'grossMarginMRQ', 'grossMarginTTM','interestCoverage',\n",
    "                      'netProfitMarginMRQ', 'netProfitMarginTTM','operatingMarginMRQ', 'operatingMarginTTM','peRatio', 'pegRatio', 'prRatio', 'quickRatio', 'returnOnAssets',\n",
    "                      'returnOnEquity', 'returnOnInvestment']] # Independent variable\n",
    "y = fundamental_data[\"Annual_Return_Percent\"] # Response / Target Variable\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "x=sm.add_constant(x)\n",
    "result=sm.OLS(y,x).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Results\n",
    "The above regression results show us that by looking at a handful of common fundamental metrics, we are able to explain only 7% of the movement in the stocks analyzed (per R-squared).  Additionally, it is usefuly to look at the Prob (F-statistic) and Prob(Jarque-Bera) as these two statistical tests are crucial gauges of model efficacy.  Specifically, if both values are under .05, we can reasonable assume the variables used in the model are meaningful indicators. \n",
    "\n",
    "While these results suggest maybe fundamental analysis isn't the best predictor, it may also be a signal that something unrelated to the companies themselves is driving performance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark: Volatility doesn't live in a vacuum\n",
    "In our previous exploration of volatility, we only examined the volatility of individual assets.  While this is certainly useful information, understanding how assets behave together can be even more insightful.  After all, who only invests in a single asset?\n",
    "\n",
    "Unlike using a weighted average to quickly find a portfolios return, we have to use the square root of the following formula to gauge a portfolio's volatility.  This is incredibly important, as often times, a portfolio can be made up of extremely volatile assets, but, because of their relationships, the net volatility is relatively low.\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/c91273fd3499f6172ed9baf853d3d3ae8d02c62d\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the formula above to find the volatility of a portfolio of half AMD and half AMC\n",
    "\n",
    "amd_weight = .5\n",
    "amc_weight = .5\n",
    "tickers = ['AMD','AMC']\n",
    "\n",
    "###Grab Price History\n",
    "price_hist = scrub_price_hist(tickers,key)\n",
    "price_hist = price_hist[['close','ticker','datetime']]\n",
    "\n",
    "\n",
    "###Calculate Portfolio Volatility\n",
    "count = 0\n",
    "for ticker in tickers:\n",
    "    if count == 0:\n",
    "        temp = price_hist[price_hist['ticker'] == ticker]\n",
    "        temp[ticker +'_Return_%'] = temp['close'] / temp['close'].shift(1) - 1\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.drop(['close','ticker'], axis = 1)\n",
    "        master = temp\n",
    "        count = 1\n",
    "    else:\n",
    "        temp = price_hist[price_hist['ticker'] == ticker]\n",
    "        temp[ticker +'_Return_%'] = temp['close'] / temp['close'].shift(1) - 1\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.drop(['close','ticker'], axis = 1)\n",
    "        master = pd.merge(master,temp,how = 'left',on = ['datetime'])\n",
    "\n",
    "\n",
    "consol_returns = pd.DataFrame([master[tickers[0] + '_Return_%']*amd_weight,master[tickers[1] + '_Return_%']*amc_weight]).T\n",
    "port_volatility = math.sqrt(consol_returns.cov().to_numpy().sum())*math.sqrt(252)\n",
    "\n",
    "###Calculate Individual Security Volatilities\n",
    "sec_vols = []        \n",
    "for ticker in tickers:\n",
    "    temp = [ticker,(math.sqrt(252)*math.sqrt(statistics.variance(master[ticker + '_Return_%'])))]\n",
    "    sec_vols.append(temp)\n",
    "    \n",
    "    \n",
    "for i in range (0,len(tickers)):\n",
    "    print(tickers[i] + ' Volatility: ',round(sec_vols[i][1]*100,2),'%')\n",
    "print('Portfolio Volatility: ',round(port_volatility*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the volatility of the portfolio is significantly less than had you only held AMC.  Conversely,  consider the implications of the volatility of these holdings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find the annualized volatility of an equally weighted portfolio of AMGN and PG.  Assume 252 trading days in a year and use one year of historicals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find the annualized volatility of AMGN and PG respecively with the same assumptions as question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Find the volatility of XRX using data from June of 2021 only.  Compare it to its volatility in September of 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD API: A Risk Management Study\n",
    "Understanding the risk of a portfolio of stocks is often times just as crucial, if not more so, than understanding its growth opportunities.  In this exercise we will examine a portfolio that has equal weights in APPL and TSLA, and attempt to gauge how much capital we are putting at risk by holding this portfolio.  To keep math simple, we will assume that the portfolio is valued at $50,000.  \n",
    "\n",
    "## Value at Risk\n",
    "Value at Risk, or simply VaR, has been around for decades, and is considered a gold standard for the benchmark of porfolio risk.  Barring any significant shifts in company health or direction, VaR can be thought of as largest paper loss an investor will see over a predefined time horizon by holding a security(s).  We will look at one month VaR, and choose a confidence level of 95% in order to have a high degree of confidence that we are in fact looking at a reasonable worst case.  While it can be beneficial to look at the 99% case, 95% will be a good start.  With our parameters defined, VaR can be calculated as follows:\n",
    "\n",
    "VaR = Portfolio Volatility * Portfolio Value * 1.65\n",
    "\n",
    "note that the 1.65 translates to a 95% confidence interval's z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define Portfolio Inputs\n",
    "aapl_weight = .5\n",
    "tsla_weight = .5\n",
    "portfolio_value = 50000\n",
    "days_into_future = 21  ##remember, a typical month only has 21 trading days\n",
    "tickers = ['TSLA','AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's calculate our portfolio volatility\n",
    "###Grab Price History\n",
    "price_hist = scrub_price_hist(tickers,key)\n",
    "price_hist = price_hist[['close','ticker','datetime']]\n",
    "\n",
    "\n",
    "###Calculate Portfolio Volatility\n",
    "count = 0\n",
    "for ticker in tickers:\n",
    "    if count == 0:\n",
    "        temp = price_hist[price_hist['ticker'] == ticker]\n",
    "        temp[ticker +'_Return_%'] = temp['close'] / temp['close'].shift(1) - 1\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.drop(['close','ticker'], axis = 1)\n",
    "        master = temp\n",
    "        count = 1\n",
    "    else:\n",
    "        temp = price_hist[price_hist['ticker'] == ticker]\n",
    "        temp[ticker +'_Return_%'] = temp['close'] / temp['close'].shift(1) - 1\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.drop(['close','ticker'], axis = 1)\n",
    "        master = pd.merge(master,temp,how = 'left',on = ['datetime'])\n",
    "\n",
    "\n",
    "consol_returns = pd.DataFrame([master[tickers[0] + '_Return_%']*tsla_weight,master[tickers[1] + '_Return_%']*aapl_weight]).T\n",
    "port_volatility = math.sqrt(consol_returns.cov().to_numpy().sum())*math.sqrt(days_into_future)\n",
    "\n",
    "###Calculate Individual Security Volatilities\n",
    "sec_vols = []        \n",
    "for ticker in tickers:\n",
    "    temp = [ticker,(math.sqrt(days_into_future)*math.sqrt(statistics.variance(master[ticker + '_Return_%'])))]\n",
    "    sec_vols.append(temp)\n",
    "\n",
    "\n",
    "\n",
    "###Compare individual security volatility to Portfolio Volatility\n",
    "for i in range (0,len(tickers)):\n",
    "    print(tickers[i] + ' Volatility: ',round(sec_vols[i][1]*100,2),'%')\n",
    "print('Portfolio Volatility: ',round(port_volatility*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calculate VaR\n",
    "VaR = portfolio_value * 1.65 * port_volatility\n",
    "print('$',round(VaR,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "By holding a \\\\$50,000 portfolio that is equally weighted in AAPL and TSLA stock, an investor should be comfortable with a significant likelihood of losing a significant amount of capital over the course of one month.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Find the 1-year value at risk for a portfolio of 25% FB and 75% MO.  Assume 252 trading days in a year, and use the most recent 1 year pricing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------EXTEND YOUR UNDERSTANDING-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume your broker allows you to invest on margin with no cost of borrowring up to 30% (i.e. for each \\\\$1 you have, you can invest \\\\$1.30).  Assume you have $10,000, want to use all the margin, and are feeling very good about an equally weighted portfolio of AIV and AIRC.  What is your one-month VaR?  Assume 21 trading days in a month, and use the most recent year's worth of data to estimate volatility.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n",
    "\n",
    "https://www.investopedia.com/financial-edge/0113/has-high-frequency-trading-ruined-the-stock-market-for-the-rest-of-us.aspx\n",
    "\n",
    "https://finmath.uchicago.edu/careers/career-paths-in-quantitative-finance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
