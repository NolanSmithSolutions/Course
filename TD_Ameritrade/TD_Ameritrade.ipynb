{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD Ameritrade – Python API\n",
    "The TD Ameritrade API allows users to easily execute trades and pull both fundamental and technical data on all public equity and debt securities.  It also offers data on publicly traded derivatives such as stock options, index & commodity futures, and interest rate swaps.\n",
    "\n",
    "### Set Up\n",
    "1.\tGo to https://developer.tdameritrade.com/\n",
    "2.\tClick “Register”\n",
    "3.\tFill in requested fields\n",
    "4.\tOnce Registered, click on “My Apps”\n",
    "5.\tSelect “Add a new App”\n",
    "6.\tFill out the fields as follows \n",
    "7.\tOnce the app is approved, click on the app name and navigate to the “KEYS” tab: \n",
    "8.\tNow that your app is registered copy the “Key” from the above section, and head over to the included Jupyter notebook to test out some of the functionality of the API.\n",
    "\n",
    "### Python Set up for the API\n",
    "Now that your app is registered, you will be able to pull a wealth of info from the API.\n",
    "#### Needed Packages\n",
    "1.\trequests\n",
    "2.\tpandas\n",
    "3.\ttime\n",
    "4.  matplotlib\n",
    "5.  numpy\n",
    "6.  seaborn\n",
    "7.  statsmodels.api\n",
    "8.  math\n",
    "9. statistics\n",
    "\n",
    "#### Needed Configuration Inputs\n",
    "1.\tTicker file path.  This is a CSV file that you will create that has the set of tickers you wish to analyze.  Place this file in your download's folder.\n",
    "2.\tAPI Key: pulled from the developer page\n",
    "3.\tDefine these required configurations in the Jupyter notebook:\n",
    "  \n",
    "\n",
    "### Data & Analysis\n",
    "\n",
    "1. Downloading fundamental data\n",
    "2. Downloading pricing data\n",
    "3. Calculating Annualized Returns\n",
    "4. Running a Regression Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###Libraries & Paths##\n",
    "######################\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Function\n",
    "\n",
    "The \"get_download_path\" function allows python to find your downloads folder's filepath and use it pull open your ticker list csv file.  The output of the below cell should be a list of the tickers you inputted in the ticker list csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_download_path():\n",
    "    \"\"\"Returns the default downloads path for linux or windows\"\"\"\n",
    "    if os.name == 'nt':\n",
    "        import winreg\n",
    "        sub_key = r'SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders'\n",
    "        downloads_guid = '{374DE290-123F-4565-9164-39C4925E467B}'\n",
    "        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, sub_key) as key:\n",
    "            location = winreg.QueryValueEx(key, downloads_guid)[0]\n",
    "        return location\n",
    "    else:\n",
    "        return os.path.join(os.path.expanduser('~'), 'downloads')\n",
    "\n",
    "ticker_path = get_download_path()+'/Ticker_List.csv'\n",
    "key = 'RGOLSJPSTGVAN4NTN4DLWJE71SU7SIH0'\n",
    "\n",
    "tickers_file = pd.read_csv(ticker_path, header=None)\n",
    "tickers = []\n",
    "for ticker in tickers_file.values:\n",
    "    tickers.append(ticker[0])\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Edits\n",
    "Uncomment out the below cell and edit the list's content to replace the tickers you wish to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tickers\n",
    "# tickers = ['TSLA','AAPL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defined Functions\n",
    "While this code block does not run anything on its own, it holds functions that will be used later in the program.  The TD Ameritrade API contains functions that don't always output data in the most clean (useable) format, so we have developed some functions that \"scrub\" the output so that it returns in a better format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_hist(ticker,period,key):\n",
    "    time.sleep(1)\n",
    "    endpoint = 'https://api.tdameritrade.com/v1/marketdata/'+ticker+'/pricehistory'\n",
    "\n",
    "    ##Define Payload\n",
    "    payload = {'apikey': key,\n",
    "    'periodType': 'year',\n",
    "    'peirod':period,\n",
    "    'frequencyType':'daily'}\n",
    "\n",
    "    ### make request\n",
    "    try:\n",
    "        content = requests.get(url = endpoint, params = payload)\n",
    "    except:\n",
    "        print('API error, please review.')\n",
    "        \n",
    "    ### Convert to dictionary\n",
    "    dictlist = []\n",
    "    data = content.json()\n",
    "\n",
    "    for key, value in data.items():\n",
    "        temp = [key,value]\n",
    "        dictlist.append(temp)\n",
    "        \n",
    "    try:\n",
    "        hist_data = pd.DataFrame(dictlist[0][1])\n",
    "        hist_data['ticker'] = ticker\n",
    "        hist_data['datetime'] = pd.to_datetime(hist_data['datetime'],unit='ms')\n",
    "        return hist_data\n",
    "    except:\n",
    "        df = pd.DataFrame()\n",
    "        return df\n",
    "    \n",
    "\n",
    "def get_fundamental_from_td(ticker,key):\n",
    "    time.sleep(1)\n",
    "    endpoint = 'https://api.tdameritrade.com/v1/instruments'\n",
    "    projection = 'fundamental'\n",
    "\n",
    "    ##Define Payload\n",
    "    payload = {'apikey': key,\n",
    "               'symbol' : ticker,\n",
    "                'projection': projection,\n",
    "                }\n",
    "    \n",
    "    ### make request\n",
    "    try:\n",
    "        content = requests.get(url = endpoint, params = payload)\n",
    "    except:\n",
    "        print('API error, please review.')\n",
    "        \n",
    "    ### Convert to dictionary\n",
    "    dictlist = []\n",
    "    data = content.json()\n",
    "    for key, value in data.items():\n",
    "        temp = [key,value]\n",
    "        dictlist.append(temp)\n",
    "        \n",
    "    try:\n",
    "        df = pd.DataFrame(dictlist[0][1]).T.reset_index(drop=True).iloc[0]\n",
    "        return df\n",
    "    except:\n",
    "        print(dictlist)\n",
    "        df = pd.DataFrame()\n",
    "        print(ticker + \" not valid.\")\n",
    "        return df\n",
    "\n",
    "def scrub_fundamental_data(tickers,key):\n",
    "    master = pd.DataFrame()\n",
    "    count = 1\n",
    "    for ticker in tickers:\n",
    "        temp = get_fundamental_from_td(ticker,key)\n",
    "        temp = pd.DataFrame(temp).T\n",
    "        hist_data = get_annual_returns([ticker],key)\n",
    "        try:\n",
    "            temp.columns = ['beta', 'bookValuePerShare', 'currentRatio', 'divGrowthRate3Year',\n",
    "           'dividendAmount', 'dividendDate', 'dividendPayAmount',\n",
    "           'dividendPayDate', 'dividendYield', 'epsChange', 'epsChangePercentTTM',\n",
    "           'epsChangeYear', 'epsTTM', 'grossMarginMRQ', 'grossMarginTTM', 'high52',\n",
    "           'interestCoverage', 'low52', 'ltDebtToEquity', 'marketCap',\n",
    "           'marketCapFloat', 'netProfitMarginMRQ', 'netProfitMarginTTM',\n",
    "           'operatingMarginMRQ', 'operatingMarginTTM', 'pbRatio', 'pcfRatio',\n",
    "           'peRatio', 'pegRatio', 'prRatio', 'quickRatio', 'returnOnAssets',\n",
    "           'returnOnEquity', 'returnOnInvestment', 'revChangeIn', 'revChangeTTM',\n",
    "           'revChangeYear', 'sharesOutstanding', 'shortIntDayToCover',\n",
    "           'shortIntToFloat', 'ticker', 'totalDebtToCapital', 'totalDebtToEquity',\n",
    "           'vol10DayAvg', 'vol1DayAvg', 'vol3MonthAvg']\n",
    "            temp = pd.merge(temp, hist_data, on='ticker')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        master = master.append(temp).reset_index(drop=True)\n",
    "        count+= 1\n",
    "    return master\n",
    "\n",
    "def scrub_price_hist(tickers,key):\n",
    "    master = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        price_data = get_price_hist(ticker,1,key)\n",
    "        master = master.append(price_data, ignore_index=True)\n",
    "    return master\n",
    "\n",
    "def get_annual_returns(tickers,key):\n",
    "    master = pd.DataFrame()\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            price_data = get_price_hist(ticker,1,key).iloc[::-1]\n",
    "            return_percent = price_data['close'].iloc[0] / price_data['close'].iloc[-1] -1\n",
    "            df = pd.DataFrame({\"ticker\":ticker,  \n",
    "                               \"Annual_Return_Percent\":return_percent},\n",
    "                               index = [0])\n",
    "            master = master.append(df, ignore_index=True)\n",
    "        except:\n",
    "\n",
    "            print('error with', ticker)\n",
    "    return master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Fundamental Data\n",
    "The below cell pulls the fundamental financial data from TD Ameritrade, cleans it up into a useable format and spits it out in a nice table format using the Pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrubbed_fundamental_data=scrub_fundamental_data(tickers,key)\n",
    "scrubbed_fundamental_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Annual Return Data\n",
    "The below cell pulls the annual return data from TD Ameritrade, cleans it up into a useable format and spits it out in a nice table format using the Pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_returns_df=get_annual_returns(tickers,key)\n",
    "annual_returns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Data Frame Info\n",
    "The next few code blocks give us information on how our data is structered, the columns it contains, the data types of the columns (string, integer, float, etc.), summary statistics, null values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in scrubbed_fundamental_data.columns:\n",
    "    try:\n",
    "        scrubbed_fundamental_data[col]=scrubbed_fundamental_data[col].astype('float')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Data columns\n",
    "scrubbed_fundamental_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General data statistics\n",
    "scrubbed_fundamental_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame information (null, data type etc)\n",
    "scrubbed_fundamental_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncorrelated features are generally more powerful predictors\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(40, 40))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=14)\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(scrubbed_fundamental_data.corr().round(2)\\\n",
    "            ,linewidths=0.1,vmax=1.0, square=True, cmap=colormap, \\\n",
    "            linecolor='white', annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scrubbed_fundamental_data[['beta', 'pcfRatio', 'returnOnAssets','quickRatio','dividendYield']] # Independent variables\n",
    "y = scrubbed_fundamental_data[\"Annual_Return_Percent\"] # Response / Target Variable\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "x=sm.add_constant(x)\n",
    "result=sm.OLS(y,x).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Results\n",
    "The above regression results show us that by only looking five fundamental metrics, we are able to explain nearly 50% of the movement in the stocks analyzed (per R-squared).  Additionally, it is usefuly to look at the Prob (F-statistic) and Prob(Jarque-Bera) as these two statistical tests are crucial gauges of model efficacy.  Specifically, if both values are under .05, we can reasonable assume the variables used in the model are meaningful indicators.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD API: A Risk Management Study\n",
    "Understanding the risk of a portfolio of stocks is often times just as crucial, if not more so, than understanding its growth opportunities.  In this exercise we will examine a portfolio that has equal weights in APPL and TSLA, and attempt to gauge how much capital we are putting at risk by holding this portfolio.  To keep math simple, we will assume that the portfolio is valued at $50,000.  \n",
    "\n",
    "## Value at Risk\n",
    "Value at Risk, or simply VaR, has been around for decades, and is considered the gold standard for the benchmark of porfolio risk.  Barring any significant shifts in company health or direction, VaR can be thought of as largest paper loss an investor will see over a predefined time horizon by holding a security(s).  We will look at one month VaR, and choose a confidence level of 95% in order to have a high degree of confidence that we are in fact looking at a reasonable worst case.  While it can be beneficial to look at the 99% case, 95% will be a good start.  With our parameters defined, VaR can be calculated as follows:\n",
    "\n",
    "VaR = Portfolio Volatility * Portfolio Value * 1.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Define Portfolio Inputs\n",
    "aapl_weight = .5\n",
    "tsla_weight = .5\n",
    "portfolio_value = 50000\n",
    "days_into_future = 30\n",
    "tickers = ['TSLA','AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Grab Price History\n",
    "price_hist = scrub_price_hist(tickers,key)\n",
    "price_hist = price_hist[['close','ticker','datetime']]\n",
    "\n",
    "\n",
    "###Calculate Portfolio Volatility\n",
    "count = 0\n",
    "for ticker in tickers:\n",
    "    if count == 0:\n",
    "        temp = price_hist[price_hist['ticker'] == ticker]\n",
    "        temp[ticker +'_Return_%'] = temp['close'] / temp['close'].shift(1) - 1\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.drop(['close','ticker'], axis = 1)\n",
    "        master = temp\n",
    "        count = 1\n",
    "    else:\n",
    "        temp = price_hist[price_hist['ticker'] == ticker]\n",
    "        temp[ticker +'_Return_%'] = temp['close'] / temp['close'].shift(1) - 1\n",
    "        temp = temp.dropna()\n",
    "        temp = temp.drop(['close','ticker'], axis = 1)\n",
    "        master = pd.merge(master,temp,how = 'left',on = ['datetime'])\n",
    "\n",
    "\n",
    "consol_returns = pd.DataFrame([master[tickers[0] + '_Return_%']*tsla_weight,master[tickers[1] + '_Return_%']*aapl_weight]).T\n",
    "port_volatility = math.sqrt(consol_returns.cov().to_numpy().sum())*math.sqrt(days_into_future)\n",
    "\n",
    "###Calculate Individual Security Volatilities\n",
    "sec_vols = []        \n",
    "for ticker in tickers:\n",
    "    temp = [ticker,(math.sqrt(days_into_future)*math.sqrt(statistics.variance(master[ticker + '_Return_%'])))]\n",
    "    sec_vols.append(temp)\n",
    "\n",
    "\n",
    "\n",
    "###Compare individual security volatility to Portfolio Volatility\n",
    "for i in range (0,len(tickers)):\n",
    "    print(tickers[i] + ' Volatility: ',round(sec_vols[i][1]*100,2),'%')\n",
    "print('Portfolio Volatility: ',round(port_volatility*100,2),'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Calculate VaR\n",
    "VaR = portfolio_value * 1.65 * port_volatility\n",
    "print('$',round(VaR,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "By holding a \\\\$50,000 portfolio that is equally weighted in AAPL and TSLA stock, an investor should be comfortable with a significant likelihood of losing \\\\$16,000+ over the course of one month.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
