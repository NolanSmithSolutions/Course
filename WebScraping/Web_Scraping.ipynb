{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![StatModels](https://www.durhamtech.edu/themes/custom/durhamtech/images/durham-tech-logo-web.svg) \n",
    "\n",
    "## Web Scraping\n",
    "\n",
    "This lecture provides foundational knowledge and examples of scraping data from live websites.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### Jupyter Overview\n",
    "#### <a href='#1'>Useful Links</a>\n",
    "#### <a href='#2'>Introduction to Jupyter Notebooks</a>\n",
    "#### <a href='#3'>Cell Types</a>\n",
    "* Markdown \n",
    "* Code\n",
    "    1. Running One Cell\n",
    "    2. Other Run Options\n",
    "\n",
    "#### <a href='#4'>Tips and Tricks</a>\n",
    "\n",
    "#### <a href='#55'>Weekly Readings/Videos</a>\n",
    "#### <a href='#56'>Extra Practice</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is web scraping and why do you need it?\n",
    "Web scraping is a catch all term for gathering information directly from web pages on the internet.  Unlike structured APIs and Databases, web scraping will require you to get creative in how you approach collecting the data as no two projects will be the same.  As an important addition to webscraping, this lecture will also cover basic use of the selenium package, which will enable you to tranverse and interact with the vast majority of moder webpages, ranging from obscure pages all the way to Facebook.\n",
    "\n",
    "In general, web scraping should be your last resort when looking to automate a data gathering exercise, as websites are prone to change over time, many web hosts do not appreciate web scraping, and, it's generally much slower than just working with prebuilt data sources.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import selenium\n",
    "from bs4 import *\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping ESPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define website url\n",
    "url = 'https://www.espn.com/nba/boxscore/_/gameId/401360104'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Open browser\n",
    "browser = webdriver.Chrome(executable_path = 'chromedriver.exe')\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Close browser\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Open browser without actually seeing it, also known as 'headless' browsing\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "browser = webdriver.Chrome(executable_path = 'chromedriver.exe',chrome_options=chrome_options)\n",
    "browser.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grab the raw webpage\n",
    "innerHTML = browser.execute_script(\"return document.body.innerHTML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parse raw webpage and close the browser (Don't want to gunk up your RAM!!)\n",
    "soup = BeautifulSoup(innerHTML,\"html.parser\")\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Find all tables on page\n",
    "tables = soup.findAll(\"table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Minutes Played</th>\n",
       "      <th>FG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J. GrantJ. GrantSF</td>\n",
       "      <td>33</td>\n",
       "      <td>5-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S. BeyS. BeySF</td>\n",
       "      <td>23</td>\n",
       "      <td>4-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I. StewartI. StewartC</td>\n",
       "      <td>27</td>\n",
       "      <td>2-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C. JosephC. JosephPG</td>\n",
       "      <td>25</td>\n",
       "      <td>3-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C. CunninghamC. CunninghamPG</td>\n",
       "      <td>28</td>\n",
       "      <td>3-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Player Minutes Played    FG\n",
       "0            J. GrantJ. GrantSF             33  5-16\n",
       "1                S. BeyS. BeySF             23  4-12\n",
       "2         I. StewartI. StewartC             27   2-6\n",
       "3          C. JosephC. JosephPG             25   3-6\n",
       "4  C. CunninghamC. CunninghamPG             28  3-13"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Grab Stats for all players on both teams & convert to dataframe\n",
    "df = []\n",
    "for table in tables:\n",
    "    for row in table.findAll(\"tr\"):\n",
    "        cells = row.findAll(\"td\")\n",
    "        cells = [ele.text.strip() for ele in cells]\n",
    "        if len(cells) == 15 and cells[0] != '' and cells[0] != 'TEAM':\n",
    "            df.append(cells[0:3])\n",
    "df = pd.DataFrame(df, columns = ['Player','Minutes Played','FG'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on anonymous web scraping and browsing\n",
    "When web scraping, many websites will blacklist your IP address in an effort to prevent you from abusing their sites.  If you are at a job and your employer is needing the data, an IP ban is not something you want ruining your day.  A common work around is to simply use a proxy server so that the website doesn't know your actual IP address.  The below will give the framework to put a proxy server between you and the internet calls you are making with python.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Proxy server list\n",
    "## 'https://proxydig.com/free-proxy-list/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Connect to a website using a proxy server\n",
    "PROXY = '209.165.163.187:3128'  ##Note that if you cannot connect to a webpage, try using a different proxy server from the site above\n",
    "url = 'https://whatismyipaddress.com/'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--proxy-server=%s' % PROXY)\n",
    "browser = webdriver.Chrome(executable_path = 'chromedriver.exe',chrome_options=chrome_options)\n",
    "browser.get(url)\n",
    "\n",
    "##NOTE: Using proxy servers will avoid most common website black listing BUT, does not substitute a VPN for security NOR\n",
    "##should you attempt to use proxy servers for nefarious activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While proxy servers enable you to avoid blacklisting, they leave you exposed from a security standpoint.  There are two common methods to add a layer of security.  The first is to always work with a VPN on before doing any web scraping, this will ensure even if someone tries to trace back to the original IP, only the VPN's will appear.  Alternatively, Selenium allows you to use the Tor browser to make internet calls.  This method is generally extremely slow, and unnecessary, but a fun exercise if you have a couple hours to spare! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a function that will open and return a headless web browser, think of variables that may be helpful to send the function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Go to: https://www.macrotrends.net/1333/historical-gold-prices-100-year-chart and scrape the table titled 'Gold Prices - Historical Annual Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an email address through python only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Open webpage\n",
    "url = 'https://mail.tutanota.com/login'\n",
    "browser = webdriver.Chrome(executable_path = 'chromedriver.exe',chrome_options=chrome_options)\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select 'More' so we can create an account\n",
    "more_button = browser.find_element_by_xpath('//*[@id=\"login-view\"]/div[2]/div/div[3]/div/button')\n",
    "more_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select 'Sign Up' so we can create an account\n",
    "sign_up_button = browser.find_element_by_xpath('//*[@id=\"login-view\"]/div[2]/div/div[4]/div/div/div/button[1]/div')\n",
    "sign_up_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select the Free option\n",
    "free_button = browser.find_element_by_xpath('//*[@id=\"upgrade-account-dialog\"]/div[2]/div[1]/div[1]/div[5]/button/div')\n",
    "free_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agree to terms\n",
    "term_1 = browser.find_element_by_xpath('//*[@id=\"modal\"]/div[2]/div/div/div/div[2]/div[1]/div/input')\n",
    "term_1.click()\n",
    "term_2 = browser.find_element_by_xpath('//*[@id=\"modal\"]/div[2]/div/div/div/div[2]/div[2]/div/input')\n",
    "term_2.click()\n",
    "ok_button = browser.find_element_by_xpath('//*[@id=\"modal\"]/div[2]/div/div/div/div[3]/button[2]/div')\n",
    "ok_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add Account Info\n",
    "email_add = browser.find_element_by_xpath('//*[@id=\"signup-account-dialog\"]/div/div[1]/div/div/div/div[1]/input')\n",
    "email_add.click()\n",
    "email_add.send_keys('test_user_abc_123') ###You will need to put in a new username!\n",
    "\n",
    "password = browser.find_element_by_xpath('//*[@id=\"signup-account-dialog\"]/div/div[2]/div[1]/div/div/div/div[1]/input[4]')\n",
    "password.click()\n",
    "password.send_keys('Sample_password!')\n",
    "\n",
    "sec_password = browser.find_element_by_xpath('//*[@id=\"signup-account-dialog\"]/div/div[2]/div[3]/div/div/div/div/input')\n",
    "sec_password.click()\n",
    "sec_password.send_keys('Sample_password!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Agree to terms 2\n",
    "term_1 = browser.find_element_by_xpath('//*[@id=\"signup-account-dialog\"]/div/div[3]/div/input')\n",
    "term_1.click()\n",
    "term_2 = browser.find_element_by_xpath('//*[@id=\"signup-account-dialog\"]/div/div[4]/div/input')\n",
    "term_2.click()\n",
    "ok_button = browser.find_element_by_xpath('//*[@id=\"signup-account-dialog\"]/div/div[5]/button/div')\n",
    "ok_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Continue\n",
    "ok_button = browser.find_element_by_xpath('//*[@id=\"wizardDialogContent\"]/div[4]/div/button/div')\n",
    "ok_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Type in Password\n",
    "password_input = browser.find_element_by_xpath('//*[@id=\"login-view\"]/div[2]/div/div[1]/form/div[2]/div/div/div/div/div/input')\n",
    "password_input.click()\n",
    "password_input.send_keys('Sample_password!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Login\n",
    "login_button = browser.find_element_by_xpath('//*[@id=\"login-view\"]/div[2]/div/div[1]/form/div[4]/button/div')\n",
    "login_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Consumer Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Open Webpage and make full screen\n",
    "url = 'https://www.bea.gov/'\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "browser = webdriver.Chrome(executable_path = 'chromedriver.exe',chrome_options=chrome_options)\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to Data section\n",
    "data = browser.find_element_by_link_text('Data')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to Data by Topic section\n",
    "data = browser.find_element_by_partial_link_text('Data by Topic')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to Consumer Spending Section\n",
    "data = browser.find_element_by_link_text('Consumer Spending')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to next Consumer Spending Section\n",
    "data = browser.find_element_by_xpath('//*[@id=\"test\"]/div[2]/article/div/div/div/ul/li[1]/a')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to Interactive Data\n",
    "data = browser.find_element_by_link_text('Interactive Data')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to Summary Tables\n",
    "data = browser.find_element_by_link_text('Summary Tables')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to Person Income and Outlays\n",
    "data = browser.find_element_by_partial_link_text('PERSONAL INCOME AND OUTLAYS')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Navigate to table 2.2A\n",
    "data = browser.find_element_by_partial_link_text('2.2A')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Download Data\n",
    "data = browser.find_element_by_xpath('//*[@id=\"showDownload\"]')\n",
    "data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Select Download Format\n",
    "data = browser.find_element_by_xpath('//*[@id=\"download_wraper\"]/div/a[2]')\n",
    "data.click()\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape current US National Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Open Webpage and make full screen\n",
    "url = 'https://www.usdebtclock.org/'\n",
    "browser = webdriver.Chrome(executable_path = 'chromedriver.exe',chrome_options=chrome_options)\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grab the raw webpage\n",
    "innerHTML = browser.execute_script(\"return document.body.innerHTML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parse raw webpage and close the browser (Don't want to gunk up your RAM!!)\n",
    "soup = BeautifulSoup(innerHTML,\"html.parser\")\n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$28,996,631,461,201\n"
     ]
    }
   ],
   "source": [
    "##Scrape the First number showing the total debt\n",
    "divs = soup.findAll(\"div\")\n",
    "count = 1\n",
    "for div in divs:\n",
    "    for row in div.findAll(\"span\"):\n",
    "        if count == 1:\n",
    "            print(row.text.strip())\n",
    "            count+=1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
