{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Applications](https://www.durhamtech.edu/themes/custom/durhamtech/images/durham-tech-logo-web.svg) \n",
    "\n",
    "## Manipulating Data with Pandas â€“ The Fundamentals\n",
    "The pandas package in python is an industry standard that allows analysts to work with small to medium data sets.  Pandas will enable an analyst to quickly clean data and gather insights.  The purpose of this lecture is to expose you to the core capabilities of the package.  This is perhaps the most important data science package as it functions in a similar way that people use excel and SQL.\n",
    "\n",
    "---\n",
    "\n",
    "### Set Up\n",
    "1.\tGo to github \n",
    "2.\tDownload the 'SPY.csv', 'Inventory_Data.csv' and 'Demand_Plan.csv' files\n",
    "3.\tMove these files to a dedicated folder on your desktop or other location\n",
    "4.\tOpen the command terminal in Anaconda Navigatory and run 'pip install pandas'\n",
    "\n",
    "\n",
    "\n",
    "### Needed Packages\n",
    "1.\tpandas\n",
    "2.  numpy\n",
    "3.  datetime\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "### The basics\n",
    "#### <a href='#1'>What are Pandas DataFrames?</a>\n",
    "#### <a href='#2'>DataFrame From 1D Array</a>\n",
    "#### <a href='#3'>DataFrame From 2D Array</a>\n",
    "#### <a href='#4'>Create DataFrame From a Dictionary</a>\n",
    "#### <a href='#5'>Create a Pandas Series Object (i.e. a DataFrame column) using a Python list</a>\n",
    "\n",
    "### Interacting with Data Frames\n",
    "#### <a href='#6'>Accessing A DataFrame</a>\n",
    "#### <a href='#7'>Attribute Access</a>\n",
    "#### <a href='#8'>Slicing Ranges</a>\n",
    "#### <a href='#9'>Selection by Position Using .iloc Attribute</a>\n",
    "#### <a href='#10'>Boolean Indexing</a>\n",
    "\n",
    "### Examing, Grouping & Describing\n",
    "#### <a href='#11'>Some Basic Statistics on a DataFrame</a>\n",
    "#### <a href='#12'>Reading in data from a CSV</a>\n",
    "#### <a href='#13'>Head & Tails</a>\n",
    "#### <a href='#14'>Filtering</a>\n",
    "#### <a href='#15'>Changing Column Attributes</a>\n",
    "#### <a href='#16'>Grouping</a>\n",
    "#### <a href='#17'>Exporting Data</a>\n",
    "\n",
    "### Combining, Editing , and Time\n",
    "#### <a href='#19'>Concatenating Frames</a>\n",
    "#### <a href='#20'>Merging Frames</a>\n",
    "#### <a href='#21'>Renaming Cells</a>\n",
    "#### <a href='#22'>Dates & Time</a>\n",
    "#### <a href='#23'>Sorting Columns</a>\n",
    "#### <a href='#24'>Shifting Columns</a>\n",
    "\n",
    "### Loops, Functions, and DataFrames\n",
    "#### <a href='#26'>Reseting an Index</a>\n",
    "#### <a href='#27'>Creating new columns from old columns</a>\n",
    "#### <a href='#28'>Lambda Functions</a>\n",
    "#### <a href='#29'>Looping through Columns</a>\n",
    "\n",
    "### Pivoting & Misc. Methods\n",
    "#### <a href='#31'>Rolling columns</a>\n",
    "#### <a href='#32'>Pivoting</a>\n",
    "#### <a href='#33'>Transpose</a>\n",
    "#### <a href='#34'>Removing Duplicates</a>\n",
    "#### <a href='#35'>Dropping Rows with Null values</a>\n",
    "#### <a href='#36'>Filling Null Values</a>\n",
    "#### <a href='#38'>Concluding Remarks</a>\n",
    "#### <a href='#55'>Weekly Readings/Videos</a>\n",
    "\n",
    "\n",
    "### Practice\n",
    "#### <a href='#39'>Exercise Set 1</a>\n",
    "#### <a href='#40'>Exercise Set 2</a>\n",
    "#### <a href='#18'>Exercise Set 3</a>\n",
    "#### <a href='#25'>Exercise Set 4</a>\n",
    "#### <a href='#30'>Exercise Set 5</a>\n",
    "#### <a href='#37'>Exercise Set 6</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## What are Pandas DataFrames?\n",
    "Pandas DataFrames are data structures that contain data organized in two dimensions, rows and columns, which are themselves organized via labels. In most cases, Pandas DataFrames are built using the DataFrame Constructor to which you can pass two-dimensional data (list, tuple and sequences, or NumPy array), dictionaries, or time series data -- to name a few data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Ensure this file is in the same folder as 'Demand_Plan.csv' & 'Inventory_Data.csv' \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "spy_path = 'SPY.csv'\n",
    "demand_path =  'Demand_Plan.csv'\n",
    "inventory_path = 'Inventory_Data.csv'\n",
    "test_path = 'test.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### DataFrame From 1D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random seed\n",
    "np.random.seed(58) \n",
    "\n",
    "# 3 different 1 dimensional arrays of length 3\n",
    "a1 = np.random.randn(3)\n",
    "a2 = np.random.randn(3)\n",
    "a3 = np.random.randn(3)\n",
    "\n",
    "print (a1)\n",
    "print (a2)\n",
    "print (a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our first DataFrame with the above numpy array\n",
    "df0 = pd.DataFrame(a1)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the dataframe gives a different result than the return value\n",
    "print(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check type\n",
    "type(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame from all 3 numpy arrays\n",
    "df0 = pd.DataFrame([a1, a2, a3])\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can set the column and index names\n",
    "df0 = pd.DataFrame([a1, a2, a3],columns=['col_a1','col_a2','col_a3'],index=['row_a','row_b','row_c'])\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding  more columns to dataframe requires that the dimensions must match\n",
    "df0['col4']=a2\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### DataFrame From 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from 2D np.array\n",
    "np.random.seed(63)\n",
    "array_2d = np.array(np.random.randn(9)).reshape(3,3)\n",
    "array_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again you can label your columns and indexes however you please\n",
    "df0 = pd.DataFrame(array_2d,columns=['1stColumn','Another_Column','ThirdOne'] \\\n",
    "                   , index=[58,12,725]) \n",
    "\n",
    "df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### Create DataFrame From a Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a Dictionary\n",
    "dict1 = {'a1':a1, 'a2':a2,'a3':a3}\n",
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the indexes\n",
    "df1 = pd.DataFrame(dict1,index=[1,2,3]) \n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add a list with strings and ints as a column \n",
    "df1['Mixed'] = [\"Apples\", 92, \"Cars\"]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### Create a Pandas Series Object (i.e. a DataFrame column) using a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every column is a series object\n",
    "type(df1['Mixed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View one column\n",
    "df1['Mixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different datatypes in a column\n",
    "print(type(df1['Mixed'][1]), type(df1['Mixed'][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series from a Python list\n",
    "s = pd.Series([21,15,32]) # an automatic index is created in numerical sequence order, 0,1,2...\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series from a Python List but with user specified list\n",
    "s2 = pd.Series([21, 15, 32], index = ['h','i','j']) #specific index\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View element\n",
    "s2['h']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='39'></a>\n",
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, create a 3x3 Data Frame with each value as '1' and add unique column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, find the type of the first row of the first column of your new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the cell below, find and print the value of the center cell of your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In the cell below, create a list with elements 'a', 'b', and 'c', transform it into a DataFrame, and find the type of the second row of the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In the cell below, creat a for loop that will creat a list of length 10 with numbers ranging from 0 to 9, then, convert this new list into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### Accessing A DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can add the Series s to the DataFrame above as column Series\n",
    "# Remember to match indices\n",
    "df1['Series'] = s\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can rename columns\n",
    "df1 = df1.rename(columns = {'Mixed':'RenamedColumn'})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can delete columns\n",
    "del df1['RenamedColumn']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or drop columns, see axis = 1 which is the step we use the most\n",
    "# however this does not change the dataframe if we don't set inplace=True\n",
    "df1.drop('a2',axis=1) # returns a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or drop rows\n",
    "df1.drop(1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a column with inplace=True\n",
    "df1.drop('Series',axis=1,inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "### Attribute Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View 1 column\n",
    "df1['a1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View several columns\n",
    "df1[['a1','a3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8'></a>\n",
    "### Slicing Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice of the DataFrame returned\n",
    "# this slices the first three rows first followed by first 2 rows of the sliced frame\n",
    "(df1[0:3][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets print the five first 2  elements of column a1\n",
    "# This is a new Series (like a new table)\n",
    "df1['a1'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the 2 columns and the top 2 values\n",
    "df1[['a1','a3']][0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='9'></a>\n",
    "### Selection by Position Using .iloc Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View element\n",
    "df1.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 2nd to 4th row, 4th to 5th column\n",
    "df1.iloc[0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also use 2 'lists' of position numbers with iloc\n",
    "df1.iloc[[0,2],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data only from row with index value '1'\n",
    "print (df1.iloc[1])\n",
    "print('\\n')\n",
    "print (df1.iloc[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='10'></a>\n",
    "### Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return  full rows where a2>0\n",
    "df1[df1['a2']>0]\n",
    "\n",
    "# The df1['a2']>0 checks condition and returns boolean (T/F)\n",
    "# The df1[] outside of it only selects the rows where this is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return column a3 values where a2 >0\n",
    "df1['a3'][df1['a2']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want the values in an np array\n",
    "npg = df1.loc[:,\"a2\"].values #otherwise it returns a  indexed series\n",
    "print(type(npg))\n",
    "print()\n",
    "npg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='40'></a>\n",
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, create a new 4x4 DataFrame of random numbers between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, print the 2nd row of the 3rd column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the cell below, create a new DataFrame using only the 1st and 3rd column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  In the cell below, create a new DataFrame from problem 1 where you include only rows where the first column is greater than .4, your answer may return an empty DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In the cell below, using the iloc method, pring the 4th row of the data frame from problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11'></a>\n",
    "### Some Basic Statistics on a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show general statistics\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only view desired, siame as slicing rows and columns in a normal dataframe\n",
    "df1.describe().loc[['mean','std'],['a2','a3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can change the index sorting\n",
    "df1.sort_index(axis=0, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='12'></a>\n",
    "### Reading in data from a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The read_csv method requires one argument, the file path, to the CSV file you want to read.\n",
    "demand_data = pd.read_csv(demand_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='13'></a>\n",
    "### Head & Tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The head method defaults to displaying the first 5 rows of a dataframe.  \n",
    "#Inputting an integer argument will adjust the number of rows displayed.\n",
    "#In this case we use 10\n",
    "demand_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tail method defaults to displaying the last 5 rows of a dataframe.  \n",
    "#Inputting an integer argument will adjust the number of rows displayed.\n",
    "demand_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='14'></a>\n",
    "### Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering in pandas works with standard python logic symbols for equal to '==', \n",
    "# greater than '>', less than '<', greater than or equal to '>=', and less than or equal to '<='.  \n",
    "# The example below shows 'demand_data' being filtered by 'Product_Family' to only include data from the 'PF_1' \n",
    "# product family.\n",
    "pf_1_demand = demand_data[demand_data['Product_Family']=='PF_1']\n",
    "pf_1_demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple filters can be applied using '&'.  \n",
    "# The below gives an example of filtering 'demand_data' \n",
    "# to only show the product family 'PF_1' at warehouse 'A'.  \n",
    "pf_1A_demand = demand_data[(demand_data['Product_Family']=='PF_1') & (demand_data['Warehouse']=='W_A')]\n",
    "pf_1A_demand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='15'></a>\n",
    "### Changing Column Attributes\n",
    "\n",
    "\n",
    "<a href ='https://numpy.org/doc/stable/reference/arrays.dtypes.html'>Data Types</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns can are automatically assigned a data type when the data is read in, but they can be changed.  \n",
    "# The below converts several columns from 'demand_data' from 'int' to 'string'.  \n",
    "# A full list of available types can be found at the link above.\n",
    "demand_data['Year'] = demand_data['Year'].astype('str')\n",
    "demand_data['Month'] = demand_data['Month'].astype('str')\n",
    "demand_data['Weeks in Month'] = demand_data['Weeks in Month'].astype('str')\n",
    "demand_data['Lookup Value'] = demand_data['Lookup Value'].astype('str')\n",
    "demand_data['SKU_ID'] = demand_data['SKU_ID'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='16'></a>\n",
    "### Grouping\n",
    "\n",
    "<a href ='https://pandas.pydata.org/docs/reference/groupby.html'>Groupby Methods</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The groupby method partitions data into groups by specified columns and \n",
    "# consolidates the numberical columns using a specified method.  \n",
    "# The below gives an example grouping 'demand_data' by 'Product_Family', \n",
    "# 'Month', and 'Year' and showing the sum of 'Demand' by product family, month, and year.  \n",
    "# A full list of methods that can be applied to the consolidated data can be found at the link above.\n",
    "data = demand_data.groupby(['Product_Family','Month','Year']).sum()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='17'></a>\n",
    "### Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below exports 'data' to a CSV located at your 'test_path'.\n",
    "data.to_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='18'></a>\n",
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the below cell, store the data from the 'Inventory_Data.csv' in the variable 'inventory_data'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the below cell, display the first 10 rows 'inventory_data'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the below cell, create a dataframe from 'demand_data' that shows the average 'Demand' by 'Warehouse', 'Month', and 'Year' for only warehouse 'W_A' and 'W_B'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In the below cell, using 'demand_data',show the basic statistics for the 'Demand' at warehouse 'W_C'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In the below cell, using 'demand_data',find the 'SKU_ID' with the highest demand for each 'Product_Family' at warehouse 'W_B'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. In the below cell, retrieve the first row of 'demand_data' and export it to a CSV with the name 'My_First_Export'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='19'></a>\n",
    "### Concatenating Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The concat method stacks frames on top of each other lining up identically named columns.  The below script stacks\n",
    "# two product famil data sets.\n",
    "pf_1 = demand_data[demand_data['Product_Family'] == 'PF_1']\n",
    "pf_2 = demand_data[demand_data['Product_Family'] == 'PF_2']\n",
    "pf_1_and_2 = pd.concat([pf_1,pf_2])\n",
    "pf_1_and_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The append method will work the same as the concat function when only working with 2 frames.  When stacking more than 2\n",
    "# frames at once, it is necessary to use concat.\n",
    "pf_1_and_2 = pf_1.append(pf_2)\n",
    "pf_1_and_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='20'></a>\n",
    "### Merging Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The merge method allows for relationships between databases.  The below does a full or 'outer' merge which will include\n",
    "# all rows from both data sets\n",
    "month_1_demand = demand_data[demand_data['Month'] == '1']\n",
    "inventory_data['SKU_ID'] = inventory_data['SKU_ID'].astype('str')\n",
    "consol_data = pd.merge(month_1_demand, inventory_data, how='outer', left_on = ['SKU_ID','Warehouse','Product_Family'],\n",
    "                       right_on = ['SKU_ID','Warehouse','Product_Family'])\n",
    "consol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below does a left merge which will include\n",
    "# all rows from month_1_demand, but only rows from inventory_data that have a matching 'SKU_ID' in month_1_demand.\n",
    "month_1_demand = demand_data[demand_data['Month'] == '1']\n",
    "inventory_data['SKU_ID'] = inventory_data['SKU_ID'].astype('str')\n",
    "consol_data = pd.merge(month_1_demand, inventory_data, how='left', left_on = ['SKU_ID','Warehouse','Product_Family'],\n",
    "                       right_on = ['SKU_ID','Warehouse','Product_Family'])\n",
    "consol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below does a right merge which will include\n",
    "# all rows from inventory_data, but only rows from month_1_demand that have a matching 'SKU_ID' in inventory_data.\n",
    "month_1_demand = demand_data[demand_data['Month'] == '1']\n",
    "inventory_data['SKU_ID'] = inventory_data['SKU_ID'].astype('str')\n",
    "consol_data = pd.merge(month_1_demand, inventory_data, how='right', left_on = ['SKU_ID','Warehouse','Product_Family'],\n",
    "                       right_on = ['SKU_ID','Warehouse','Product_Family'])\n",
    "consol_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='21'></a>\n",
    "### Renaming Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below renames the 'Lookup Value' column to 'Unique_ID'\n",
    "demand_data = demand_data.rename(columns={\"Lookup Value\": \"Unique_ID\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='22'></a>\n",
    "### Dates & Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 'to_datetime' method converts a pandas column to a datetime object\n",
    "spy_data = pd.read_csv(spy_path)\n",
    "spy_data['Date'] = pd.to_datetime(spy_data['Date'])\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime objects have many attributes including month, day, and year.  \n",
    "spy_data['Month'] = pd.DatetimeIndex(spy_data['Date']).month\n",
    "spy_data['Year'] = pd.DatetimeIndex(spy_data['Date']).year\n",
    "spy_data['Day'] = pd.DatetimeIndex(spy_data['Date']).day\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below is a quick algorithm to map in quarter\n",
    "spy_data['Quarter'] = (spy_data['Month'] -1) // 3 + 1\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates can be modified formulaicly using the timedelta method. The below creates a new column 30 days ahead of the date\n",
    "# column. \n",
    "spy_data['Date_+_30'] = spy_data['Date'] + timedelta(days=30)\n",
    "spy_data.head()\n",
    "spy_data = spy_data.drop(columns=['Date_+_30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='23'></a>\n",
    "### Sorting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'sort_values' method sorts the data be a provided column name\n",
    "spy_data = spy_data.sort_values(by=['Date'], ascending=False)\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='24'></a>\n",
    "### Shifting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below shows a use of the shift method which moves a column up or down a specified integer number of columns\n",
    "# relative to the rest of the data.  we also remove some unnecessary columns\n",
    "spy_data = spy_data.drop(columns=['Open','High','Low','Close','Volume'])\n",
    "spy_data['Return_%'] = spy_data['Adj Close']/spy_data['Adj Close'].shift(-1)-1\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='25'></a>\n",
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, Find all demand_data for 'Product_Family' 'PF_3', then, use the merge method to pull in the inventory positions for those SKUs.  Your final data set should contain no rows with blank 'Demand'.  Output your data to CSV title 'PF_3_All_Data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, mirror the DataFrame created in the section on shifting, except calculate the two day return instead of the daily return.  You will need to read in the SPY data again, and ensure to drop 'Open', 'High','Low','Close',and 'Volume'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the cell below, find the average daily return of SPY for February, 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Pull the demand data for 'Product_Family' 'PF_1' in month '1', and inventory data for 'Product_Family' PF_2.  Concatenate these two Dataframes and include a new column to the resulting DataFrame specifying which data source each row of data is from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the daily standard deviation of the returns of SPY for March of 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='26'></a>\n",
    "### Reseting an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the index of the below frame is not sequenced correctly. \n",
    "pf_1 = demand_data[demand_data['Product_Family'] == 'PF_1']\n",
    "pf_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reset_index method resets the index of a frame.  Note that the old index will need to be dropped, as python\n",
    "# will by default make it a new column\n",
    "pf_1.reset_index(inplace = True)\n",
    "pf_1.drop(columns = ['index'], inplace = True)\n",
    "pf_1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='27'></a>\n",
    "### Creating new columns from old columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using columns to create new columns works very similarly to standar python variables.  The below creates a new\n",
    "# ID combining the 'Year','Month', and 'Weeks in Month' columns. \n",
    "pf_1['New_ID'] = pf_1['Year'] + pf_1['Month'] + pf_1['Weeks in Month']\n",
    "pf_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='28'></a>\n",
    "### Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda functions are a way to create new operations when methods don't exist for them, and still avoiding using for loops.  \n",
    "# The below lambda function creates a new column that finds the squared value of 'Adj Close'\n",
    "spy_data['Price Squared'] = spy_data['Adj Close'].map(lambda x: x ** 2)\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='29'></a>\n",
    "### Looping through Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loops can be applied to a list of columns in a data frame to apply methods and functions to multiple columns rapidly\n",
    "spy_data = pd.read_csv(spy_path)\n",
    "target_cols = ['Open','High','Low','Close']\n",
    "for col in target_cols:\n",
    "    spy_data[col + '_Price Squared'] = spy_data[col].map(lambda x: x ** 2)\n",
    "    \n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='30'></a>\n",
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, design a lambda function that will multiply the column by 4, then add 5.  Apply this function to the 'Low' and 'High' columns in 'spy_data' using a for loop, you will need to read in the data again.  Come up with a naming conventory to uniquely identify your new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, find all demand data for month '1' from 'demand_data', merge the 'inventory_data' onto it, and create a new column that calculates the ratio of demand to inventory for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In the cell below, find all of the inventory_data at warehouse 'W_A'.  Then reset the resulting DataFrame's index, and be sure to the new DataFrame does not have any new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In the cell below, find all of the inventory_data at warehouse 'W_C'. Then reset the resulting DataFrame's index, and be sure to the new DataFrame does not have any new columns.  Then, sort the resulting DataFrame by inventory amount in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. In the cell below, create a DataFrame from 'spy_data' that only shows data from the 3rd quarter of 2021.  Assume a standard calendar year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='31'></a>\n",
    "### Rolling columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rolling method will calculate a rollow operation on a column to create a new column.   The below column calculates \n",
    "# rolling 30 day average ETF price of SPY. \n",
    "spy_data = pd.read_csv(spy_path)\n",
    "spy_data['Date'] = pd.to_datetime(spy_data['Date'])\n",
    "spy_data = spy_data.sort_values(by=['Date'], ascending=True)\n",
    "spy_data.reset_index(inplace = True)\n",
    "spy_data.drop(columns = 'index',inplace = True)\n",
    "spy_data = spy_data.drop(columns=['Open','High','Low','Close','Volume'])\n",
    "spy_data['30-Day Average Price'] = spy_data['Adj Close'].rolling(30).mean()\n",
    "spy_data = spy_data.sort_values(by=['Date'], ascending=False)\n",
    "spy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='32'></a>\n",
    "### Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pivot table, just as in excel, allows you to quickly consolidate data around defined columns.  Very similar\n",
    "# in concept to the groupby method.  \n",
    "pd.pivot_table(demand_data, values = 'Demand', index=['Warehouse','Product_Family']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='33'></a>\n",
    "### Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Transpose method, as in linear algebra, will transpose a dataframe as if it were a matrix\n",
    "test = pd.DataFrame([[0,1,2,3,4],[0,1,2,3,4],[0,1,2,3,4]])\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not how the transpose has rotated each column\n",
    "\n",
    "test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='34'></a>\n",
    "### Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that test has 3 copies of the same row.  The drop_duplicates will remove the extra copies\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='35'></a>\n",
    "### Dropping Rows with Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the null value in the first row.  To remove rows with null values, the dropna function will work\n",
    "test = pd.DataFrame([[0,2,3,4],[0,1,2,3,4],[0,1,2,3,4]])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='36'></a>\n",
    "### Filling Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fillna method allows you to keep rows with null values, and control what fills them.  In the below, 0 replaces\n",
    "# null values\n",
    "test.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='37'></a>\n",
    "## -------------PRACTICE-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cell below, find the rolling 30 day standard deviation of the daily returns for the SPY from January 2021 through September 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the cell below, create a lamda function that will create a new column in spy_data with '1' for days with positive returns, and null for days without.  Drop days null values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Go finance.yahoo.com, and download the historical data of your favorite stock or ETF for September of 2021.  Then, import the data, sort it in descending order, transpose it, then export it to a CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Read in a fresh pull of your new stock data and SPY data, then do a left merge of the data, with your new stock being the left DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Using the DataFrame from question 4, create a new column that shows the difference in returns between SPY and your security. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='55'></a>\n",
    "# Weekly Readings/Videos\n",
    "\n",
    "https://www.thinkful.com/blog/what-is-data-science/\n",
    "    \n",
    "https://hbr.org/2013/11/how-to-start-thinking-like-a-data-scientist\n",
    "\n",
    "http://www.tylervigen.com/spurious-correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='38'></a>\n",
    "# Concluding Remarks\n",
    "Pandas continues to evolve and offer more and more capabilities.  While this lecture covers the rudimentary aspects of the packs, you will find as you work with it more, you will continue to find new methods, and ways to combine it with other python functionalities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
